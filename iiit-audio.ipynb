{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9836550,"sourceType":"datasetVersion","datasetId":6033840},{"sourceId":10005761,"sourceType":"datasetVersion","datasetId":6159227}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import Sampler\nfrom sklearn.metrics import normalized_mutual_info_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:02:45.549117Z","iopub.execute_input":"2024-11-25T09:02:45.549870Z","iopub.status.idle":"2024-11-25T09:02:45.554606Z","shell.execute_reply.started":"2024-11-25T09:02:45.549839Z","shell.execute_reply":"2024-11-25T09:02:45.553823Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class UnifLabelSampler(Sampler):\n    \"\"\"Samples elements uniformely accross pseudolabels.\n        Args:\n            N (int): size of returned iterator.\n            images_lists: dict of key (target), value (list of data with this target)\n    \"\"\"\n\n    def __init__(self, N, images_lists):\n        self.N = N\n        self.images_lists = images_lists\n        self.indexes = self.generate_indexes_epoch()\n\n    def generate_indexes_epoch(self):\n        nmb_non_empty_clusters = 0\n        for i in range(len(self.images_lists)):\n            if len(self.images_lists[i]) != 0:\n                nmb_non_empty_clusters += 1\n\n        size_per_pseudolabel = int(self.N / nmb_non_empty_clusters) + 1\n        res = np.array([])\n\n        for i in range(len(self.images_lists)):\n            # skip empty clusters\n            if len(self.images_lists[i]) == 0:\n                continue\n            indexes = np.random.choice(\n                self.images_lists[i],\n                size_per_pseudolabel,\n                replace=(len(self.images_lists[i]) <= size_per_pseudolabel)\n            )\n            res = np.concatenate((res, indexes))\n\n        np.random.shuffle(res)\n        res = list(res.astype('int'))\n        if len(res) >= self.N:\n            return res[:self.N]\n        res += res[: (self.N - len(res))]\n        return res\n\n    def __iter__(self):\n        return iter(self.indexes)\n\n    def __len__(self):\n        return len(self.indexes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:02:48.715122Z","iopub.execute_input":"2024-11-25T09:02:48.715902Z","iopub.status.idle":"2024-11-25T09:02:48.723617Z","shell.execute_reply.started":"2024-11-25T09:02:48.715870Z","shell.execute_reply":"2024-11-25T09:02:48.722732Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport torch\nwith open('/kaggle/input/iiitb-audio/dev_feat_encoded.pkl', 'rb') as f:\n    data2 = pickle.load(f)\n\n\ndatalist2 = []\nfor item in data2:\n    for row in data2[item]:\n        datalist2.append(row.reshape(11,39))\ndatalist2=np.asarray(datalist2, dtype=np.float32)\nprint(datalist2.shape)\nX=torch.from_numpy(datalist2)\nX=torch.unsqueeze(X,1)\nprint(X.shape)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:02:50.325260Z","iopub.execute_input":"2024-11-25T09:02:50.325928Z","iopub.status.idle":"2024-11-25T09:02:52.092389Z","shell.execute_reply.started":"2024-11-25T09:02:50.325876Z","shell.execute_reply":"2024-11-25T09:02:52.091542Z"}},"outputs":[{"name":"stdout","text":"(148377, 11, 39)\ntorch.Size([148377, 1, 11, 39])\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/input/iiitb-audio/train_feat_encoded.pkl','rb') as f:\n    data3 = pickle.load(f)\ndatalist3 = []\nfor item in data3:\n    for row in data3[item]:\n        datalist3.append(row.reshape(11,39))\ndatalist3=np.asarray(datalist3, dtype=np.float32)\nprint(datalist3.shape)\nY=torch.from_numpy(datalist3)\nY=torch.unsqueeze(Y,1)\nprint(Y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:02:56.963212Z","iopub.execute_input":"2024-11-25T09:02:56.963552Z","iopub.status.idle":"2024-11-25T09:03:11.621910Z","shell.execute_reply.started":"2024-11-25T09:02:56.963521Z","shell.execute_reply":"2024-11-25T09:03:11.621036Z"}},"outputs":[{"name":"stdout","text":"(1363869, 11, 39)\ntorch.Size([1363869, 1, 11, 39])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\n\n# Assuming X is already created and processed as per your provided code\n\n# Step 2: Create a Dataset from the tensor X\ndataset = TensorDataset(X)\nprint(dataset)\n# Step 3: Use a DataLoader to create batches of data\nbatch_size = 256\ntest_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:03:11.623262Z","iopub.execute_input":"2024-11-25T09:03:11.623532Z","iopub.status.idle":"2024-11-25T09:03:11.629804Z","shell.execute_reply.started":"2024-11-25T09:03:11.623507Z","shell.execute_reply":"2024-11-25T09:03:11.629022Z"}},"outputs":[{"name":"stdout","text":"<torch.utils.data.dataset.TensorDataset object at 0x7819d402d120>\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Assuming X is already created and processed as per your provided code\n\n# Step 2: Create a Dataset from the tensor X\ndataset1 = TensorDataset(Y)\nprint(dataset1)\n# Step 3: Use a DataLoader to create batches of data\nbatch_size = 256\ntrain_loader = DataLoader(dataset1, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:03:11.630941Z","iopub.execute_input":"2024-11-25T09:03:11.631545Z","iopub.status.idle":"2024-11-25T09:03:11.640324Z","shell.execute_reply.started":"2024-11-25T09:03:11.631507Z","shell.execute_reply":"2024-11-25T09:03:11.639529Z"}},"outputs":[{"name":"stdout","text":"<torch.utils.data.dataset.TensorDataset object at 0x7819d402d3c0>\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import sys\n\n# Add the directory containing `clus.py` to the Python path\nsys.path.append('/kaggle/input/iiitbdata')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:03:17.809406Z","iopub.execute_input":"2024-11-25T09:03:17.809746Z","iopub.status.idle":"2024-11-25T09:03:17.814132Z","shell.execute_reply.started":"2024-11-25T09:03:17.809715Z","shell.execute_reply":"2024-11-25T09:03:17.813221Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"!pip install faiss-gpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:03:36.144559Z","iopub.execute_input":"2024-11-25T09:03:36.145254Z","iopub.status.idle":"2024-11-25T09:03:48.026220Z","shell.execute_reply.started":"2024-11-25T09:03:36.145221Z","shell.execute_reply":"2024-11-25T09:03:48.025109Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import clus\ndeepcluster = clus.__dict__[\"Kmeans\"](39)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:03:54.912879Z","iopub.execute_input":"2024-11-25T09:03:54.913211Z","iopub.status.idle":"2024-11-25T09:03:55.003461Z","shell.execute_reply.started":"2024-11-25T09:03:54.913183Z","shell.execute_reply":"2024-11-25T09:03:55.002784Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:04:23.163971Z","iopub.execute_input":"2024-11-25T09:04:23.164665Z","iopub.status.idle":"2024-11-25T09:04:23.170248Z","shell.execute_reply.started":"2024-11-25T09:04:23.164634Z","shell.execute_reply":"2024-11-25T09:04:23.169214Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Define the Convolutional Neural Network model\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.cnt = 1\n        self.conv1 = nn.Sequential(         \n            nn.Conv2d(\n                in_channels=1,              \n                out_channels=16,            \n                kernel_size=5,              \n                stride=1,                   \n                padding=2,                  \n            ),                              \n            nn.ReLU(),                      \n            nn.MaxPool2d(kernel_size=2),    \n        )\n        self.conv2 = nn.Sequential(         \n            nn.Conv2d(16, 32, 5, 1, 2),     \n            nn.ReLU(),                      \n            nn.MaxPool2d(2),                \n        )\n        self.fc1 = nn.Sequential(nn.Dropout(0.5),\n                            nn.Linear(36 * 4 * 4, 256),\n                            nn.ReLU(inplace=True),\n                            nn.Dropout(0.5),\n                            nn.Linear(256, 256),\n                            nn.ReLU(inplace=True))\n        \n        # fully connected layer, output 10 classes\n        self.out = nn.Linear(256, 39)\n    def forward(self, x):\n        if self.cnt:\n            print(f'input={x.shape}')\n        x = self.conv1(x)\n        if self.cnt:\n            print(f'first CNN output={x.shape}')\n        x = self.conv2(x)\n        if self.cnt:\n            print(f'second CNN output={x.shape}')\n        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n        x = x.view(x.size(0), -1)    \n        if self.cnt:\n            print(f'flatten output={x.shape}')\n        x = self.fc1(x)  \n        if self.cnt:\n            print(f'fc1={x.shape}')\n        if self.out:\n            x = self.out(x)\n        \n        if self.cnt:\n            print(f'output layer output={x.shape}')\n            self.cnt = 0\n        return  x    # return x for visualization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:04:41.008687Z","iopub.execute_input":"2024-11-25T09:04:41.009039Z","iopub.status.idle":"2024-11-25T09:04:41.017629Z","shell.execute_reply.started":"2024-11-25T09:04:41.009010Z","shell.execute_reply":"2024-11-25T09:04:41.016714Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"cnn = CNN()\ncnn.out=None\nprint(cnn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:04:46.557702Z","iopub.execute_input":"2024-11-25T09:04:46.558083Z","iopub.status.idle":"2024-11-25T09:04:46.583027Z","shell.execute_reply.started":"2024-11-25T09:04:46.558053Z","shell.execute_reply":"2024-11-25T09:04:46.582136Z"}},"outputs":[{"name":"stdout","text":"CNN(\n  (conv1): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc1): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=576, out_features=256, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=256, out_features=256, bias=True)\n    (5): ReLU(inplace=True)\n  )\n  (out): None\n)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#loss function\nloss_func = nn.CrossEntropyLoss()   \nloss_func","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:04:52.145257Z","iopub.execute_input":"2024-11-25T09:04:52.145594Z","iopub.status.idle":"2024-11-25T09:04:52.151724Z","shell.execute_reply.started":"2024-11-25T09:04:52.145562Z","shell.execute_reply":"2024-11-25T09:04:52.150668Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"CrossEntropyLoss()"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# optimizer\noptimizer = optim.Adam(cnn.parameters(), lr = 0.001)   \noptimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:04:56.957940Z","iopub.execute_input":"2024-11-25T09:04:56.958603Z","iopub.status.idle":"2024-11-25T09:04:56.964292Z","shell.execute_reply.started":"2024-11-25T09:04:56.958571Z","shell.execute_reply":"2024-11-25T09:04:56.963494Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def compute_features(dataloader, N):\n    cnn.eval()\n    for i, images in enumerate(dataloader):\n        b_x = Variable(images[0])   # batch x\n        with torch.no_grad():\n             aux = cnn(b_x)\n        aux = aux.cpu().numpy()\n  \n        if i == 0:\n            features = np.zeros((N, aux.shape[1]), dtype='float32')\n\n        aux = aux.astype('float32')\n        if i < len(dataloader) - 1:\n            features[i * batch_size: (i + 1) * batch_size] = aux\n        else:\n            # special treatment for final batch\n            features[i * batch_size:] = aux\n    return features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:08:04.708795Z","iopub.execute_input":"2024-11-25T09:08:04.709686Z","iopub.status.idle":"2024-11-25T09:08:04.715283Z","shell.execute_reply.started":"2024-11-25T09:08:04.709652Z","shell.execute_reply":"2024-11-25T09:08:04.714345Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class ReassignedDataset():\n    \"\"\"A dataset where the new images labels are given in argument.\n    Args:\n        image_indexes (list): list of data indexes\n        pseudolabels (list): list of labels for each data\n        dataset (list): list of tuples with paths to images\n        transform (callable, optional): a function/transform that takes in\n                                        an PIL image and returns a\n                                        transformed version\n    \"\"\"\n\n    def __init__(self, image_indexes, pseudolabels, dataset, transform=None):\n        self.imgs = self.make_dataset(image_indexes, pseudolabels, dataset)\n        self.transform = transform\n\n    def make_dataset(self,image_indexes, pseudolabels, dataset):\n        label_to_idx = {label: idx for idx, label in enumerate(set(pseudolabels))}\n        images = []\n        for j, idx in enumerate(image_indexes):\n            img = dataset[idx]  # Retrieve the image from the dataset\n            pseudolabel = label_to_idx[pseudolabels[j]]\n            images.append((img, pseudolabel))\n        return images\n\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index (int): index of data\n        Returns:\n            tuple: (image, pseudolabel) where pseudolabel is the cluster of the index datapoint\n        \"\"\"\n        img, pseudolabel = self.imgs[index]\n        # img is already a tensor, so no need to load it with pil_loader\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, pseudolabel\n\n\n    def __len__(self):\n        return len(self.imgs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:08:05.359150Z","iopub.execute_input":"2024-11-25T09:08:05.359492Z","iopub.status.idle":"2024-11-25T09:08:05.366362Z","shell.execute_reply.started":"2024-11-25T09:08:05.359462Z","shell.execute_reply":"2024-11-25T09:08:05.365460Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def cluster_assign(images_lists, dataset):\n    \"\"\"Creates a dataset from clustering, with clusters as labels.\n    Args:\n        images_lists (list of list): for each cluster, the list of image indexes\n                                    belonging to this cluster\n        dataset (list): initial dataset\n    Returns:\n        ReassignedDataset(torch.utils.data.Dataset): a dataset with clusters as\n                                                     labels\n    \"\"\"\n    assert images_lists is not None\n    pseudolabels = []\n    image_indexes = []\n    for cluster, images in enumerate(images_lists):\n        image_indexes.extend(images)\n        pseudolabels.extend([cluster] * len(images))\n    return ReassignedDataset(image_indexes, pseudolabels, dataset, None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:08:05.982709Z","iopub.execute_input":"2024-11-25T09:08:05.983423Z","iopub.status.idle":"2024-11-25T09:08:05.988451Z","shell.execute_reply.started":"2024-11-25T09:08:05.983391Z","shell.execute_reply":"2024-11-25T09:08:05.987341Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def per_epoch(epochs, num_epochs, cnn, loader, train):\n\n    if train:\n        cnn.train()\n        optimizer_tl = torch.optim.SGD(cnn.out.parameters(),lr=0.01, weight_decay=10**-5)\n    else:\n        cnn.eval()\n        \n    # Train the model\n    total_step = len(loader)\n    #print(total_step)\n    total_loss = 0.0\n    total_acc = 0.0\n        \n    for i, (images, labels) in enumerate(loader):\n        # gives batch data, normalize x when iterate train_loader\n        b_x = Variable(images)\n        # batch x\n        b_y = Variable(labels)   # batch y\n        output= cnn(b_x) \n\n        loss = loss_func(output, b_y)\n        total_loss+= loss.item()\n        pred_y = torch.max(output, 1)[1].data.squeeze()\n        accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n        total_acc += accuracy\n        if train:\n            # clear gradients for this training step   \n            optimizer.zero_grad() \n            optimizer_tl.zero_grad()\n        \n            # backpropagation, compute gradients \n            loss.backward()\n            #for name, param in cnn.named_parameters():\n                #if param.grad is not None:\n                    #print(f'Gradient of {name}: {param.grad.abs().mean().item()}')\n            # apply gradients             \n            optimizer.step()\n            optimizer_tl.step()\n        \n        if (i+1) % 300 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} Acc: {:.4f} ' \n                   .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), accuracy))\n    return (total_loss/total_step), (total_acc/total_step)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:08:12.007913Z","iopub.execute_input":"2024-11-25T09:08:12.008254Z","iopub.status.idle":"2024-11-25T09:08:12.016039Z","shell.execute_reply.started":"2024-11-25T09:08:12.008223Z","shell.execute_reply":"2024-11-25T09:08:12.015026Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:08:19.193635Z","iopub.execute_input":"2024-11-25T09:08:19.193993Z","iopub.status.idle":"2024-11-25T09:08:19.198714Z","shell.execute_reply.started":"2024-11-25T09:08:19.193962Z","shell.execute_reply":"2024-11-25T09:08:19.197601Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"tr_loss_epoch,  val_loss_epoch,  tr_acc_epoch,  val_acc_epoch = [], [], [], []\nnmi_list1=[]\nnmi_list=[]\nprev_assignments = None\nnum_epochs = 100\nnum_epochs = 100\nleast_loss = 9999\nlogdir='mnist_output'\nprint(logdir)\n# Create the output folder\ntry:\n    os.stat(logdir)\nexcept:\n    os.makedirs(logdir)\n\nfor epoch in range(0, num_epochs):\n    cnn.out=None\n    train_features = compute_features(train_loader, len(Y))\n    test_features=compute_features(test_loader, len(X))\n    # cluster the feature\n    clustering_loss = deepcluster.cluster(train_features,test_features, verbose=False)\n    \n    # assign pseudo-labels\n    train_dataset = cluster_assign(deepcluster.images_lists, Y)\n   \n    # uniformly sample per target\n    sampler = UnifLabelSampler(int(1 * len(train_dataset)), deepcluster.images_lists)\n\n    train_dataloader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        num_workers=1,\n        sampler=sampler,\n        pin_memory=True,\n    )\n   \n    # assign pseudo-labels\n    test_dataset = cluster_assign(deepcluster.images_lists1, X)\n\n    sampler = UnifLabelSampler(int(1 * len(test_dataset)), deepcluster.images_lists1)\n\n    test_dataloader = torch.utils.data.DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        num_workers=1,\n        sampler=sampler,\n        pin_memory=True,\n    )\n    cnn.out= nn.Linear(256, 39)\n    \n    tr_loss, tr_acc = per_epoch(epoch, num_epochs, cnn, train_dataloader, train=True)\n    tr_loss_epoch.append(tr_loss), tr_acc_epoch.append(tr_acc)\n    val_loss, val_acc = per_epoch(epoch, num_epochs, cnn, test_dataloader, train=False)\n    val_loss_epoch.append(val_loss), val_acc_epoch.append(val_acc)\n    print ('Epoch {}, Train Loss: {:.4f} train Acc: {:.4f} Val Loss: {:.4f} Val Acc: {:.4f} ' \n                   .format(epoch, tr_loss, tr_acc, val_loss, val_acc))\n    train_file = open(logdir + '/train_log.txt',\"a\")\n    train_file.write(\"Epoch {}: train: [loss-{:.6f} error-{:.6f} ], val: [loss-{:.6f} error-{:.6f}]\\n\".                 \n              format(epoch, tr_loss, tr_acc, val_loss, val_acc))\n    train_file.close()\n\n    if val_loss < least_loss:\n        min_loss_epoch = epoch\n        torch.save(cnn.state_dict(), logdir+'/best_loss_model.pth')\n        least_loss = val_loss \n\n\n    current_assignments = np.zeros(len(Y))\n    for cluster_id, indices in enumerate(deepcluster.images_lists):\n        for index in indices:\n            current_assignments[index] = cluster_id\n\n  \n    # Calculate NMI if there is a previous assignment\n    if prev_assignments is not None:\n        nmi = normalized_mutual_info_score(prev_assignments, current_assignments)\n        nmi_list.append(nmi)\n        print(f'Epoch {epoch}, NMI {nmi}')\n    train_file = open(logdir + '/train_log.txt',\"a\")\n    if prev_assignments is not None:\n        train_file.write(\"NMI between previous and current assignments {}\\n\".format(nmi))\n    train_file.close()\n    # Update previous assignments\n    prev_assignments = current_assignments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T09:08:24.565291Z","iopub.execute_input":"2024-11-25T09:08:24.565973Z","iopub.status.idle":"2024-11-25T09:14:43.429722Z","shell.execute_reply.started":"2024-11-25T09:08:24.565940Z","shell.execute_reply":"2024-11-25T09:14:43.428294Z"}},"outputs":[{"name":"stdout","text":"mnist_output\ninput=torch.Size([256, 1, 11, 39])\nfirst CNN output=torch.Size([256, 16, 5, 19])\nsecond CNN output=torch.Size([256, 32, 2, 9])\nflatten output=torch.Size([256, 576])\nfc1=torch.Size([256, 256])\noutput layer output=torch.Size([256, 256])\nEpoch [1/100], Step [300/5328], Loss: 3.6225 Acc: 0.0586 \nEpoch [1/100], Step [600/5328], Loss: 3.6107 Acc: 0.0469 \nEpoch [1/100], Step [900/5328], Loss: 3.6099 Acc: 0.0469 \nEpoch [1/100], Step [1200/5328], Loss: 3.6221 Acc: 0.0586 \nEpoch [1/100], Step [1500/5328], Loss: 3.6177 Acc: 0.0625 \nEpoch [1/100], Step [1800/5328], Loss: 3.6313 Acc: 0.0469 \nEpoch [1/100], Step [2100/5328], Loss: 3.5962 Acc: 0.0703 \nEpoch [1/100], Step [2400/5328], Loss: 3.6002 Acc: 0.0625 \nEpoch [1/100], Step [2700/5328], Loss: 3.5860 Acc: 0.0625 \nEpoch [1/100], Step [3000/5328], Loss: 3.6251 Acc: 0.0391 \nEpoch [1/100], Step [3300/5328], Loss: 3.6059 Acc: 0.0664 \nEpoch [1/100], Step [3600/5328], Loss: 3.6141 Acc: 0.0430 \nEpoch [1/100], Step [3900/5328], Loss: 3.6167 Acc: 0.0430 \nEpoch [1/100], Step [4200/5328], Loss: 3.6341 Acc: 0.0508 \nEpoch [1/100], Step [4500/5328], Loss: 3.6144 Acc: 0.0430 \nEpoch [1/100], Step [4800/5328], Loss: 3.5993 Acc: 0.0586 \nEpoch [1/100], Step [5100/5328], Loss: 3.6080 Acc: 0.0586 \nEpoch [1/100], Step [300/580], Loss: 3.6563 Acc: 0.0430 \nEpoch 0, Train Loss: 3.6157 train Acc: 0.0507 Val Loss: 3.6230 Val Acc: 0.0498 \nEpoch [2/100], Step [300/5328], Loss: 1.9847 Acc: 0.4727 \nEpoch [2/100], Step [600/5328], Loss: 2.2249 Acc: 0.4219 \nEpoch [2/100], Step [900/5328], Loss: 1.9752 Acc: 0.5078 \nEpoch [2/100], Step [1200/5328], Loss: 2.3093 Acc: 0.4102 \nEpoch [2/100], Step [1500/5328], Loss: 2.2446 Acc: 0.4570 \nEpoch [2/100], Step [1800/5328], Loss: 1.9410 Acc: 0.5195 \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 51\u001b[0m\n\u001b[1;32m     42\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     43\u001b[0m     test_dataset,\n\u001b[1;32m     44\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     49\u001b[0m cnn\u001b[38;5;241m.\u001b[39mout\u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m39\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m tr_loss, tr_acc \u001b[38;5;241m=\u001b[39m \u001b[43mper_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m tr_loss_epoch\u001b[38;5;241m.\u001b[39mappend(tr_loss), tr_acc_epoch\u001b[38;5;241m.\u001b[39mappend(tr_acc)\n\u001b[1;32m     53\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m per_epoch(epoch, num_epochs, cnn, test_dataloader, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","Cell \u001b[0;32mIn[24], line 20\u001b[0m, in \u001b[0;36mper_epoch\u001b[0;34m(epochs, num_epochs, cnn, loader, train)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# batch x\u001b[39;00m\n\u001b[1;32m     19\u001b[0m b_y \u001b[38;5;241m=\u001b[39m Variable(labels)   \u001b[38;5;66;03m# batch y\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m output\u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_x\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output, b_y)\n\u001b[1;32m     23\u001b[0m total_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[15], line 34\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnt:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnt:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst CNN output=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/pooling.py:164\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_jit_internal.py:503\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:796\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    795\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}